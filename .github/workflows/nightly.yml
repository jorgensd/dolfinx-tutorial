# This is a basic workflow to help you get started with Actions
name: Test against DOLFINx nightly build

# Controls when the action will run.
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [dokken/jupyterbook]
  pull_request:
    branches:
      - dokken/jupyterbook

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

  # Test every day at 9 am
  schedule:
    - cron: "* 9 * * 1"

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  test-against-master:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    container: dolfinx/lab:nightly

    env:
      HDF5_MPI: "ON"
      PYVISTA_OFF_SCREEN: true

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      - name: Reinstall hdf5 with zlib enabled
        run: |
          export HDF5_SERIES=1.12
          export HDF5_PATCH=2
          wget -nc --quiet https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-${HDF5_SERIES}/hdf5-${HDF5_SERIES}.${HDF5_PATCH}/src/hdf5-${HDF5_SERIES}.${HDF5_PATCH}.tar.gz
          tar xfz hdf5-${HDF5_SERIES}.${HDF5_PATCH}.tar.gz
          cmake -G Ninja -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release -DHDF5_ENABLE_PARALLEL=on -DHDF5_ENABLE_Z_LIB_SUPPORT=on -B build-dir -S hdf5-${HDF5_SERIES}.${HDF5_PATCH}
          cmake --build build-dir
          cmake --install build-dir


      - name: Install dependencies
        run: |
          pip3 install --upgrade pip setuptools
          CC=mpicc HDF_MPI="ON" HDF5_DIR="/usr/local/" pip3 install --no-cache-dir -r docker/requirements.txt
          apt-get -qq update
          apt-get install -y libgl1-mesa-dev xvfb nodejs
          apt-get clean
          rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
          rm -rf /usr/local/share/.cache/*
          ls /root/shared/.local/share/
          ls /github/home/.local/share/
      - name: Test complex notebooks in parallel
        run: |
          export PKG_CONFIG_PATH=/usr/local/dolfinx-complex/lib/pkgconfig:$PKG_CONFIG_PATH
          export PETSC_ARCH=linux-gnu-complex-32
          export PYTHONPATH=/usr/local/dolfinx-complex/lib/python3.10/dist-packages:$PYTHONPATH
          export LD_LIBRARY_PATH=/usr/local/dolfinx-complex/lib:$LD_LIBRARY_PATH
          cd chapter1
          mpirun -n 2 python3 complex_mode.py
 
      - name: Test real notebooks in parallel
        run: |
          cd chapter1
          python3 -c "from pyvista import start_xvfb; start_xvfb(0.1)"
          mpirun -n 2 python3 fundamentals_code.py
          mpirun -n 2 python3 nitsche.py
          mpirun -n 2 python3 membrane_code.py
          cd ../chapter2
          mpirun -n 2 python3 diffusion_code.py
          mpirun -n 2 python3 heat_code.py
          mpirun -n 2 python3 linearelasticity_code.py
          mpirun -n 2 python3 hyperelasticity.py
          mpirun -n 2 python3 nonlinpoisson_code.py
          mpirun -n 2 python3 ns_code1.py
          mpirun -n 2 python3 ns_code2.py
          cd ../chapter3
          mpirun -n 3 python3 neumann_dirichlet_code.py
          mpirun -n 3 python3 multiple_dirichlet.py
          mpirun -n 3 python3 subdomains.py
          mpirun -n 3 python3 robin_neumann_dirichlet.py
          mpirun -n 3 python3 component_bc.py
          mpirun -n 3 python3 em.py
          cd ../chapter4
          mpirun -n 3 python3 solvers.py
          mpirun -n 3 python3 convergence.py
          mpirun -n 3 python3 compiler_parameters.py
          mpirun -n 4 python3 newton-solver.py

      - name: Test building the book
        run: 
          PYVISTA_JUPYTER_BACKEND=static PYVISTA_OFF_SCREEN=false jupyter-book build  -W .
